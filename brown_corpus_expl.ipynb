{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Digital Assignment 1\n",
    "### Submitted by: Alvin Manoj Alex\n",
    "### Reg no: 20BCE1020\n",
    "### Question 1: Explore the Brown corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import NLTK and Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown Corpus and its size, tokens and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury']\n"
     ]
    }
   ],
   "source": [
    "words = brown.words()\n",
    "print(words[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']]\n"
     ]
    }
   ],
   "source": [
    "sents = brown.sents()\n",
    "print(sents[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categories of this corpus are  ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print(\"The categories of this corpus are \",brown.categories())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of this corpus is (number of words)  1161192\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of this corpus is (number of words) \",len(words))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of word types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokens of this corpus are (unique words)  56057\n"
     ]
    }
   ],
   "source": [
    "print(\"The tokens of this corpus are (unique words) \",len(set(words)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of the 'government' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the corpus in government category is  70117\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the corpus in government category is \",len(brown.words(categories='government')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The most frequent tokens used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most Frequently Used Tokens:\n",
      "the : 62713\n",
      ", : 58334\n",
      ". : 49346\n",
      "of : 36080\n",
      "and : 27915\n"
     ]
    }
   ],
   "source": [
    "frequency = {}\n",
    "for word in words:\n",
    "    if word in frequency:\n",
    "        frequency[word] += 1\n",
    "    else:\n",
    "        frequency[word] = 1\n",
    "\n",
    "# Sort the dictionary by frequency\n",
    "sorted_frequency = sorted(frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the most frequently used tokens\n",
    "print(\"The 5 most Frequently Used Tokens:\")\n",
    "for i in range(5):\n",
    "    print(sorted_frequency[i][0], \":\", sorted_frequency[i][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sentences in this corpus is  57340\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of sentences in this corpus is \",len(sents))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9fddff257f2474a94b6dc1ed79677df2511cea0d61e12891bc16708bacd76e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
